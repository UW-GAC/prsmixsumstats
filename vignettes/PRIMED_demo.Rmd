---
title: "Calculating summary statistics for elastic net"
author: "Dan Schaid"
date: "`r Sys.Date()`"
output: html_document
vignette: >
  %\VignetteIndexEntry{Calculating summary statistics}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```


```{r}
library(prsmixsumstats)
```

Simulate test data of 3 groups with PRS (nprs) and covariates (sex, age, covs)

```{r}
nprs <- 500
n1 <- 100
n2 <- 200
n3 <- 100

dat1 <- sim_test_dat(n1, nprs)
dat2 <- sim_test_dat(n2, nprs)
dat3 <- sim_test_dat(n3, nprs)
```

# Biobanks Create Summary Statistics (3 demo biobanks)

```{r}
sumstat1 <- make_sumstats(dat1$x, dat1$y)
sumstat2 <- make_sumstats(dat2$x, dat2$y)
sumstat3 <- make_sumstats(dat3$x, dat3$y)
sumstats_all <- list(sumstat1, sumstat2, sumstat3)
```

# CC: sum over biobanks

```{r}
combo_sumstats <- combine_sumstats(sumstats_all)

sumstats <- combo_sumstats$sumstats
sumstats$vary <- combo_sumstats$yvar
```

# Fit glmnet_sumstats for a grid of alpha's & lambda's

```{r}
penalty_factor <- rep(1,ncol(sumstats$xx))


## alpha weights abs(beta) and (1-alpha) weights beta^2
alpha_grid <- seq(from=0.9, to=0.1, by= -0.2)
lambda_frac <- exp(seq(from=log(1), to=log(.05), length=10))


nlambda <- length(lambda_frac)
nalpha <- length(alpha_grid)

## note 2-dimensional grid of fits. Each fit is a list
## and all fits arranged as matrix (of lists)

fit_grid <- matrix(list(), nrow=nalpha, ncol=nlambda)

maxiter <- 50

beta_zero <- rep(0, ncol(sumstats$xx))
max_xy <- max(abs(sumstats$xy))

time_begin <-  proc.time()
for(i in 1:nalpha){
  alpha <- alpha_grid[i]
  lambda_max <- max_xy/alpha
  
  for(j in 1:nlambda){
    lambda <- lambda_frac[j]*lambda_max
    cat("================ alpha = ", alpha, ", lambda.frac = ", lambda_frac[j], ", lambda = ", lambda, " ==================\n")
    
    if(i==1 & j==1){
      beta_init <- beta_zero
    } else if (i > 1 & j == 1){
      beta_init <- fit_grid[[i-1,j]]$beta   ## use warm start for next fit
    } else {
      beta_init <- fit_grid[[i,j-1]]$beta   ## use warm start for next fit
    }
    
    ptm <- proc.time()
    fit_grid[[i,j]] <-  glmnet_sumstats(sumstats, beta_init, alpha=alpha, lambda=lambda, penalty_factor,  maxiter=500, tol=1e-5, verbose=FALSE)
    print(proc.time() - ptm)
  }
}
```


## metrics for training data

```{r}

metrics_train <- metrics_sumstats(sumstats, fit_grid)

```

## Simulate data to choose penalty alpha and lambda

```{r}
set.seed(123)

nsim <- 5

vmat <- make_var_matrix(sumstats)
time_begin <-  proc.time()
wishart_sim <- sim_sumstats(vmat, nsim=nsim)
print(proc.time() - time_begin)
```

## plot loss across grid

```{r}
loss_sim <- eval_sim(wishart_sim, fit_grid, sumstats$vary)

loss_mean <- loss_sim$loss_mean
loss_sd   <- loss_sim$loss_sd

grid_indices <- loss_indices(loss_mean, loss_sd)

# Convert to long format for plotting
library(reshape2)

colnames(loss_mean) <- lambda_frac
rownames(loss_mean) <- alpha_grid
mat_long <- melt(loss_mean)
names(mat_long) <- c("alpha", "lambda", "loss")

mat_long$label <- rep("above", nrow(mat_long))

index_mat_to_vec <- function(i,j,nrow){
  k <-  i+(j - 1)*nrow
  return(k)
}
kmin <- index_mat_to_vec(grid_indices$loss_min_index[1], grid_indices$loss_min_index[2], nrow(loss_mean))
mat_long$label[kmin] <- "min"

k1sd <- index_mat_to_vec(grid_indices$loss_1sd_index[1], grid_indices$loss_1sd_index[2], nrow(loss_mean))
mat_long$label[k1sd] <- "min+1sd"

titl <- paste0("Loss across grid")

library(ggplot2)

ggplot(mat_long, aes(x = lambda, y = alpha, color = label)) + 
  geom_point(aes(size = loss)) +
  scale_color_manual(values = c("min" = "red", "min+1sd" = "blue", "above" = "black")) +
  labs(title = titl, x = "lambda_frac", y = "alpha")
```

## No. Beta's Selected

```{r}
countmin <- table(abs(fit_grid[[grid_indices$loss_min_index[1], grid_indices$loss_min_index[2]]]$beta) > 1e-6)
count1sd <- table(abs(fit_grid[[grid_indices$loss_1sd_index[1], grid_indices$loss_1sd_index[2]]]$beta) > 1e-6)

rbind(countmin, count1sd)
```


